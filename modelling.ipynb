{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "\n",
    "with open(\"helper_functions.py\") as f:\n",
    "    code = compile(f.read(), \"helper_functions.py\", 'exec')\n",
    "    exec(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in train data..\n",
      "Reading in test data..\n",
      "Running feature extraction process..\n",
      "Dropping unused variables..\n",
      "Running data preparation for train dataset\n",
      "Encoding labels of the outcome variable..\n",
      "Using one hot encoding for predictor variables..\n",
      "Running data preparation for test dataset\n",
      "Encoding labels of the outcome variable..\n",
      "Using one hot encoding for predictor variables..\n",
      "Columns are the same!!\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.RandomState(0)\n",
    "\n",
    "print ('Reading in train data..')\n",
    "train = pd.read_csv('train.csv')\n",
    "train['type'] = 'train'\n",
    "\n",
    "print ('Reading in test data..')\n",
    "test = pd.read_csv('test.csv')\n",
    "test['type'] = 'test'\n",
    "test['OutcomeSubtype'] = ''\n",
    "test['OutcomeType'] = ''\n",
    "\n",
    "df = data_import(train, test)\n",
    "\n",
    "print ('Running data preparation for train dataset')\n",
    "X_train, y_train, le_train, X_train_cols = prep_data(df, 'train')\n",
    "\n",
    "print ('Running data preparation for test dataset')\n",
    "X_test, y_test, le_test, X_test_cols = prep_data(df, 'test')\n",
    "\n",
    "col_check(X_train_cols, X_test_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score is 0.6711437015975158\n",
      "Predicting outcomes..\n",
      "Correct number of rows\n",
      "Saving to CSV..\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "gbm = xgb.XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.05).fit(X_train, y_train)\n",
    "print ('Model score is %r' % gbm.score(X_train, y_train))\n",
    "predict_output(gbm, 'xgboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the model to the training dataset..\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "gbm = xgb.XGBClassifier()\n",
    "pipe = Pipeline(steps=[('gbm', gbm)])\n",
    "\n",
    "n_estimators = [20, 50, 100, 200, 500]\n",
    "max_depth = [3, 4, 5]\n",
    "learning_rate = [0.1, 0.05, 0.01]\n",
    "n_comp = list(range(1, X_train.shape[1] + 1))\n",
    "\n",
    "estimator_gbm = GridSearchCV(pipe, dict(\n",
    "                              gbm__n_estimators = n_estimators,\n",
    "                              gbm__max_depth=max_depth,\n",
    "                              gbm__learning_rate = learning_rate))\n",
    "\n",
    "print ('Fitting the model to the training dataset..')\n",
    "estimator_gbm.fit(X_train, y_train)\n",
    "\n",
    "best_score = estimator_gbm.best_score_\n",
    "best_est = estimator_gbm.best_estimator_\n",
    "\n",
    "print ('Best score is %r for GBM' % best_score)\n",
    "print ('best estimators are as follows \\n %r' % best_est)\n",
    "\n",
    "predict_output(estimator_gbm, 'xgboost_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score is 0.67125593924202176 for GBM\n",
      "best estimators are as follows \n",
      " Pipeline(steps=[('gbm', XGBClassifier(base_score=0.5, colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "       max_delta_step=0, max_depth=5, min_child_weight=1, n_estimators=200,\n",
      "       nthread=-1, objective='multi:softprob', seed=0, silent=True,\n",
      "       subsample=1))])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating pipeline of PCA and Logistic Regression\n",
      "Fitting estimator on train dataset..\n",
      "Best results for Logistic Regression\n",
      "0.630064723708\n",
      "Pipeline(steps=[('pca', PCA(copy=True, n_components=44, whiten=False)), ('logistic', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import linear_model, decomposition\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "logistic = linear_model.LogisticRegression()\n",
    "\n",
    "pca = decomposition.PCA()\n",
    "pipe = Pipeline(steps=[('pca', pca), ('logistic', logistic)])\n",
    "\n",
    "n_comp = list(range(1, X_train.shape[1] + 1))\n",
    "Cs = np.logspace(-4, 4, 3)\n",
    "penalty = ['l1', 'l2']\n",
    "\n",
    "print ('Estimating pipeline of PCA and Logistic Regression')\n",
    "\n",
    "estimator_lr = GridSearchCV(pipe,\n",
    "                         dict(pca__n_components=n_comp,\n",
    "                              logistic__C=Cs, logistic__penalty=penalty), n_jobs=-1)\n",
    "\n",
    "print ('Fitting estimator on train dataset..')\n",
    "estimator_lr.fit(X_train, y_train)\n",
    "\n",
    "best_score = estimator_lr.best_score_\n",
    "best_est = estimator_lr.best_estimator_\n",
    "\n",
    "print ('Best score is %r for Logistic Regression' % best_score)\n",
    "print ('best estimators are as follows \\n %r' % best_est)\n",
    "\n",
    "predict_output(estimator_lr, 'pca_logit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the model to the training dataset..\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "pipe = Pipeline(steps=[('pca', pca), ('rf', rf)])\n",
    "\n",
    "n_estimators = [20, 50, 100]\n",
    "max_depth = [3, None]\n",
    "min_samples_split = [1, 3, 10]\n",
    "min_samples_leaf = [1, 3, 10]\n",
    "bootstrap = [True, False]\n",
    "criterion = [\"gini\", \"entropy\"]\n",
    "\n",
    "n_comp = list(range(1, X_train.shape[1] + 1))\n",
    "\n",
    "estimator_rf = GridSearchCV(pipe,\n",
    "                         dict(pca__n_components=n_comp,\n",
    "                              rf__n_estimators = n_estimators,\n",
    "                              rf__max_depth=max_depth,\n",
    "                              rf__min_samples_split = min_samples_split,\n",
    "                              rf__min_samples_leaf = min_samples_leaf,\n",
    "                              rf__bootstrap = bootstrap,\n",
    "                              rf__criterion = criterion), n_jobs = -1)\n",
    "\n",
    "print ('Fitting the model to the training dataset..')\n",
    "estimator_rf.fit(X_train, y_train)\n",
    "\n",
    "best_score = estimator_rf.best_score_\n",
    "best_est = estimator_rf.best_estimator_\n",
    "\n",
    "print ('Best results for Random Forest')\n",
    "print (best_score)\n",
    "print (best_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
