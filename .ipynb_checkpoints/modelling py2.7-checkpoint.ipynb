{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "\n",
    "with open(\"helper_functions.py\") as f:\n",
    "    code = compile(f.read(), \"helper_functions.py\", 'exec')\n",
    "    exec(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in train data..\n",
      "Reading in test data..\n",
      "Running feature extraction process..\n",
      "Dropping unused variables..\n",
      "Running data preparation for train dataset\n",
      "Encoding labels of the outcome variable..\n",
      "Using one hot encoding for predictor variables..\n",
      "Running data preparation for test dataset\n",
      "Encoding labels of the outcome variable..\n",
      "Using one hot encoding for predictor variables..\n",
      "Columns are the same!!\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.RandomState(0)\n",
    "\n",
    "print ('Reading in train data..')\n",
    "train = pd.read_csv('train.csv')\n",
    "train['type'] = 'train'\n",
    "\n",
    "print ('Reading in test data..')\n",
    "test = pd.read_csv('test.csv')\n",
    "test['type'] = 'test'\n",
    "test['OutcomeSubtype'] = ''\n",
    "test['OutcomeType'] = ''\n",
    "\n",
    "df = data_import(train, test)\n",
    "\n",
    "print ('Running data preparation for train dataset')\n",
    "X_train, y_train, le_train, X_train_cols = prep_data(df, 'train')\n",
    "\n",
    "print ('Running data preparation for test dataset')\n",
    "X_test, y_test, le_test, X_test_cols = prep_data(df, 'test')\n",
    "\n",
    "col_check(X_train_cols, X_test_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the model to the training dataset..\n",
      "Best score is 0.67421153054734562 for GBM\n",
      "best estimators are as follows \n",
      " Pipeline(steps=[('imp', Imputer(axis=0, copy=True, missing_values=nan, strategy='median', verbose=0)), ('gbm', XGBClassifier(base_score=0.5, colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "       max_delta_step=0, max_depth=5, min_child_weight=1, n_estimators=200,\n",
      "       nthread=-1, objective='multi:softprob', seed=0, silent=True,\n",
      "       subsample=1))])\n",
      "Predicting outcomes..\n",
      "Correct number of rows\n",
      "Saving to CSV..\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "gbm = xgb.XGBClassifier()\n",
    "imp = Imputer(missing_values=np.nan, axis=0)\n",
    "\n",
    "pipe = Pipeline(steps=[('imp', imp), ('gbm', gbm)])\n",
    "\n",
    "strat = ['median']\n",
    "\n",
    "n_estimators = [20, 50, 100, 200, 500]\n",
    "max_depth = [3, 4, 5]\n",
    "learning_rate = [0.1, 0.05, 0.01]\n",
    "n_comp = list(range(1, X_train.shape[1] + 1))\n",
    "\n",
    "est_space = dict(imp__strategy = strat,\n",
    "                  gbm__n_estimators = n_estimators,\n",
    "                  gbm__max_depth=max_depth,\n",
    "                  gbm__learning_rate = learning_rate)\n",
    "\n",
    "estimator_gbm = GridSearchCV(pipe, param_grid=est_space, n_jobs=-1, cv=5)\n",
    "\n",
    "print ('Fitting the model to the training dataset..')\n",
    "estimator_gbm.fit(X_train, y_train)\n",
    "\n",
    "best_score = estimator_gbm.best_score_\n",
    "best_est = estimator_gbm.best_estimator_\n",
    "\n",
    "print ('Best score is %r for GBM' % best_score)\n",
    "print ('best estimators are as follows \\n %r' % best_est)\n",
    "\n",
    "predict_output(estimator_gbm, 'xgboost_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the model to the training dataset..\n",
      "Best score is 0.67353810468030972 for GBM\n",
      "best estimators are as follows \n",
      " Pipeline(steps=[('imp', Imputer(axis=0, copy=True, missing_values=nan, strategy='mean', verbose=0)), ('gbm', XGBClassifier(base_score=0.5, colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "       max_delta_step=0, max_depth=5, min_child_weight=1, n_estimators=200,\n",
      "       nthread=-1, objective='multi:softprob', seed=0, silent=True,\n",
      "       subsample=1))])\n",
      "Predicting outcomes..\n",
      "Correct number of rows\n",
      "Saving to CSV..\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "strat = ['mean']\n",
    "\n",
    "n_estimators = [20, 50, 100, 200, 500]\n",
    "max_depth = [3, 4, 5]\n",
    "learning_rate = [0.1, 0.05, 0.01]\n",
    "n_comp = list(range(1, X_train.shape[1] + 1))\n",
    "\n",
    "est_space = dict(imp__strategy = strat,\n",
    "                  gbm__n_estimators = n_estimators,\n",
    "                  gbm__max_depth=max_depth,\n",
    "                  gbm__learning_rate = learning_rate)\n",
    "\n",
    "estimator_gbm = GridSearchCV(pipe, param_grid=est_space, n_jobs=-1, cv=5)\n",
    "\n",
    "print ('Fitting the model to the training dataset..')\n",
    "estimator_gbm.fit(X_train, y_train)\n",
    "\n",
    "best_score = estimator_gbm.best_score_\n",
    "best_est = estimator_gbm.best_estimator_\n",
    "\n",
    "print ('Best score is %r for GBM' % best_score)\n",
    "print ('best estimators are as follows \\n %r' % best_est)\n",
    "\n",
    "predict_output(estimator_gbm, 'xgboost_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the model to the training dataset..\n",
      "Best score is 0.67421153054734562 for GBM\n",
      "best estimators are as follows \n",
      " Pipeline(steps=[('imp', Imputer(axis=0, copy=True, missing_values=nan, strategy='most_frequent',\n",
      "    verbose=0)), ('gbm', XGBClassifier(base_score=0.5, colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "       max_delta_step=0, max_depth=5, min_child_weight=1, n_estimators=200,\n",
      "       nthread=-1, objective='multi:softprob', seed=0, silent=True,\n",
      "       subsample=1))])\n",
      "Predicting outcomes..\n",
      "Correct number of rows\n",
      "Saving to CSV..\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "strat = ['most_frequent']\n",
    "\n",
    "n_estimators = [20, 50, 100, 200, 500]\n",
    "max_depth = [3, 4, 5]\n",
    "learning_rate = [0.1, 0.05, 0.01]\n",
    "n_comp = list(range(1, X_train.shape[1] + 1))\n",
    "\n",
    "est_space = dict(imp__strategy = strat,\n",
    "                  gbm__n_estimators = n_estimators,\n",
    "                  gbm__max_depth=max_depth,\n",
    "                  gbm__learning_rate = learning_rate)\n",
    "\n",
    "estimator_gbm = GridSearchCV(pipe, param_grid=est_space, n_jobs=-1, cv=5)\n",
    "\n",
    "print ('Fitting the model to the training dataset..')\n",
    "estimator_gbm.fit(X_train, y_train)\n",
    "\n",
    "best_score = estimator_gbm.best_score_\n",
    "best_est = estimator_gbm.best_estimator_\n",
    "\n",
    "print ('Best score is %r for GBM' % best_score)\n",
    "print ('best estimators are as follows \\n %r' % best_est)\n",
    "\n",
    "predict_output(estimator_gbm, 'xgboost_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbm = xgb.XGBClassifier()\n",
    "imp = Imputer(missing_values=np.nan, strategy = 'median', axis=0)\n",
    "\n",
    "pipe = Pipeline(steps=[('imp', imp), ('gbm', gbm)])\n",
    "\n",
    "n_estimators = [20, 50, 100, 200, 500]\n",
    "max_depth = [3, 4, 5]\n",
    "learning_rate = [0.1, 0.05, 0.01]\n",
    "n_comp = list(range(1, X_train.shape[1] + 1))\n",
    "\n",
    "est_space = dict(imp__strategy = strat,\n",
    "                  gbm__n_estimators = n_estimators,\n",
    "                  gbm__max_depth=max_depth,\n",
    "                  gbm__learning_rate = learning_rate)\n",
    "\n",
    "estimator_gbm = GridSearchCV(pipe, param_grid=est_space, n_jobs=-1, cv=5)\n",
    "\n",
    "print ('Fitting the model to the training dataset..')\n",
    "estimator_gbm.fit(X_train, y_train)\n",
    "\n",
    "best_score = estimator_gbm.best_score_\n",
    "best_est = estimator_gbm.best_estimator_\n",
    "\n",
    "print ('Best score is %r for GBM' % best_score)\n",
    "print ('best estimators are as follows \\n %r' % best_est)\n",
    "\n",
    "predict_output(estimator_gbm, 'xgboost_tuned')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
